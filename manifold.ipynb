{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import Config\n",
    "import Dataloader as DL\n",
    "import HD_basis as HDB\n",
    "import HD_encoder as HDE\n",
    "import HD_classifier as HDC\n",
    "\n",
    "import sklearn.manifold as skm \n",
    "import sklearn.utils.random as skr # for random sampling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data \n",
    "def train(hdc, traindata, trainlabels, testdata, testlabels, param = Config.config):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    # Early stopping \n",
    "    epsilon = 0.001\n",
    "    counter = 0\n",
    "    for _ in tqdm_notebook(range(param[\"epochs\"]), desc='epochs'):\n",
    "        train_acc.append(hdc.fit(traindata, trainlabels, param))\n",
    "        test_acc.append(hdc.test(testdata, testlabels))\n",
    "        if len(train_acc) % 5 == 0:\n",
    "            print(\"Train: %f \\t \\t Test: %f\"%(train_acc[-1], test_acc[-1]))\n",
    "        if train_acc[-1] == 1:\n",
    "            print(\"Train: %f \\t \\t Test: %f\"%(train_acc[-1], test_acc[-1]))\n",
    "            break\n",
    "        if max(test_acc) - test_acc[-1] >= epsilon:\n",
    "            counter += 1\n",
    "            #if counter >= 20:\n",
    "            #    sys.stderr.write(\"Early stopping initiated\")\n",
    "            #    print(\"Train: %f \\t \\t Test: %f\"%(train_acc[-1], test_acc[-1]))\n",
    "            #    break\n",
    "        else:\n",
    "            counter = 0\n",
    "    return np.asarray(train_acc), np.asarray(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_log(param, train_acc, test_acc, filename):\n",
    "    joblib.dump((param, train_acc, test_acc), open(filename+\".pkl\", \"wb\"), compress=True)\n",
    "    file = open(filename+\".txt\", \"a\")\n",
    "    msg = str(100*max(train_acc)) + \" \" + str(100*max(test_acc)) + \" \" +\\\n",
    "        str(len(train_acc)) + \" \" + str(np.argmax(test_acc) + 1) + \"\\n\"\n",
    "    file.write(msg)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ISOMAP ########################\n",
    "# Everyone uses a neighborhood size of 8-12.\n",
    "# If your manifold is more than 2-3 dimensional, then Isomap probably won't work, \n",
    "# you would need to have a neighborhood size that is larger (more points!) so that \n",
    "# you have reasonable options to estimate your geodesic path with links to nearby neighbors.\n",
    "def iso_wrapper(n_neighbors, n_components):\n",
    "    \n",
    "    start = time.time()\n",
    "    isomap = skm.Isomap(n_neighbors, n_components)\n",
    "    isomap.fit(manifolddata)\n",
    "    end = time.time()\n",
    "    # Preparation time \n",
    "    prep_time = int(end - start) \n",
    "    print( \"Prep time: \", prep_time ) \n",
    "    \n",
    "    start = time.time()\n",
    "    trainiso = isomap.transform(traindata)\n",
    "    testiso = isomap.transform(testdata)\n",
    "    end = time.time() \n",
    "    # Transformation time\n",
    "    trans_time = int(end-start)\n",
    "    print( \"Transform time: \", trans_time )\n",
    "\n",
    "    filename = \"./dumper/isomap_data_\"+str(n_neighbors)+\"_\"+str(n_components)+\".pkl\"\n",
    "    joblib.dump((trainiso, trainlabels, testiso, testlabels), open(filename, \"wb\"), compress=True)\n",
    "    \n",
    "    return trainiso, testiso, prep_time, trans_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Modified/Hessian Locally Linear Embedding , more ########################\n",
    "\n",
    "def lle_wrapper(n_neighbors, n_components, lle_type = \"modified\"):\n",
    "    \n",
    "    start = time.time()\n",
    "    mlle = skm.LocallyLinearEmbedding(n_neighbors, n_components, method = lle_type)\n",
    "    mlle.fit(manifolddata)\n",
    "    end = time.time()\n",
    "    prep_time = int(end - start) \n",
    "    print( prep_time ) \n",
    "\n",
    "    start = time.time()\n",
    "    trainmlle = mlle.transform(traindata)\n",
    "    testmlle = mlle.transform(testdata)\n",
    "    end = time.time()\n",
    "    trans_time = int(end-start)\n",
    "    print( trans_time )\n",
    "\n",
    "    file_name = \"./dumper/\"+lle_type+\"_data_\"+str(n_neighbors)+\"_\"+str(n_components)+\".pkl\"\n",
    "    joblib.dump((trainmlle, trainlabels, testmlle, testlabels), open(filename, \"wb\"), compress=True)\n",
    "\n",
    "    return trainiso, testiso, prep_time, trans_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Spectral Embedding ########################\n",
    "############### Multi-dimensional Scaling ########################\n",
    "############### t-distributed Stochastic Neighbor Embedding #######\n",
    "# No online learning version; has to input full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset MNIST from MNIST\n",
      "Loading train data... train data of shape (60000, 784) loaded\n",
      "Loading test data...  test  data of shape (10000, 784) loaded\n",
      "Data Loaded. Num of features = 784 Num of Classes = 10"
     ]
    }
   ],
   "source": [
    "dl = DL.Dataloader()\n",
    "nFeatures, nClasses, traindata, trainlabels, testdata, testlabels = dl.getParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cropping\n",
    "traindata = traindata[:20000]\n",
    "testdata = testdata[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_location': '../dataset/', 'directory': 'MNIST', 'dataset': 'MNIST', 'D': 500, 'vector': 'Gaussian', 'mu': 0, 'sigma': 1, 'binarize': 0, 'lr': 0.037, 'sparse': 0, 's': 0.1, 'binaryModel': 0, 'width': None, 'height': None, 'nLayers': 5, 'uniform_dim': 1, 'uniform_ker': 1, 'dArr': None, 'k': 5, 'kArr': None, 'one_shot': 0, 'data_percentages': [1.0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5], 'train_percent': 1, 'dropout': 0, 'drop_percentages': [0, 0.1, 0.2, 0.5], 'dropout_rate': 0, 'update_type': <Update_T.FULL: 1>, 'iter_per_trial': 3, 'iter_per_encoding': 5, 'epochs': 250, 'nFeatures': 784, 'nClasses': 10, 'id': '3505', 'gen_type': <Generator.Vanilla: 1>, 'manifold': 'isomap'}\n"
     ]
    }
   ],
   "source": [
    "param = Config.config\n",
    "param[\"nFeatures\"] = nFeatures\n",
    "param[\"nClasses\"] = nClasses\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run manifolding learning data\n",
    "# Random sampling for manifold \n",
    "\n",
    "#manifoldlist = skr.sample_without_replacement(len(traindata), 2000)\n",
    "#manifolddata = np.asfarray(traindata[np.asarray(manifoldlist)])\n",
    "#n_neighbors = 200\n",
    "#n_components  = 25\n",
    "#param[\"nFeatures\"] = n_components\n",
    "#traintrans, testtrans, prep_time, trans_time = iso_wrapper(n_neighbors, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run basiline data \n",
    "# param[\"nFeatures\"] = nFeatures\n",
    "# param[\"manifold\"] = \"baseline\"\n",
    "# traintrans, testtrans = traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# VANILLA #################\n",
    "def vanilla_train(param):\n",
    "    hdb = HDB.HD_basis(HDB.Generator.Vanilla, param)\n",
    "    basis = hdb.getBasis()\n",
    "    bid = hdb.getParam()[\"id\"]\n",
    "    # Update param with bid\n",
    "    param = hdb.getParam()\n",
    "    print(bid)\n",
    "\n",
    "    hde = HDE.HD_encoder(basis)\n",
    "    trainencoded = hde.encodeData(traintrans)\n",
    "    #trainencoded = hde.encodeData(traindata)\n",
    "    HDE.saveEncoded(trainencoded, trainlabels, bid, \"train\")\n",
    "    testencoded = hde.encodeData(testtrans)\n",
    "    #testencoded = hde.encodeData(testdata)\n",
    "    HDE.saveEncoded(testencoded, testlabels, bid, \"test\")\n",
    "\n",
    "    # Should have 95%\n",
    "    for i in range(param[\"iter_per_encoding\"]):\n",
    "        hdc = HDC.HD_classifier(param[\"D\"], param[\"nClasses\"], bid)\n",
    "        train_acc, test_acc = train(hdc, trainencoded, trainlabels, testencoded, testlabels, param)\n",
    "    \n",
    "    return train_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension tuning \n",
    "param[\"D\"] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep time:  18\n"
     ]
    }
   ],
   "source": [
    "for i in range(param[\"iter_per_trial\"]):\n",
    "    \n",
    "    # Run manifolding learning data\n",
    "    # Random sampling for manifold \n",
    "    manifoldlist = skr.sample_without_replacement(len(traindata), 2000)\n",
    "    manifolddata = np.asfarray(traindata[np.asarray(manifoldlist)])\n",
    "    n_neighbors = 200\n",
    "    n_components  = 25\n",
    "    param[\"nFeatures\"] = n_components\n",
    "    param[\"manifold\"] = \"isomap\"\n",
    "    traintrans, testtrans, prep_time, trans_time = iso_wrapper(n_neighbors, n_components)\n",
    "    \n",
    "    train_acc, test_acc = vanilla_train(param)\n",
    "    \n",
    "    #filename = \"./logfile/\" + param[\"manifold\"] + \"_\" +str(param[\"D\"])+\"_\"+str(param[\"id\"])\n",
    "    filename = \"./logfile/\" + param[\"manifold\"] + \"_\" +str(param[\"D\"])+\"_\"+ \\\n",
    "        str(n_components) + \"_\" + str(n_neighbors) + \"_\" + str(param[\"id\"])\n",
    "    dump_log(param, train_acc, test_acc, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
